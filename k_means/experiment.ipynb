{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means\n",
    "\n",
    "For this problem, you will be implementing the K-Means algorithm. This is an unsupervised learning algorithm for clustering problems. That is, its objective is to produce a partitioning over a dataset without (explicit) external supervision of which group each datapoint should belong to.\n",
    "\n",
    "Your initial implementation should be a standard K-means algorithm with Euclidean distance metric. A concise description can be found in [Andrew NG's lecture notes on K-Means](http://cs229.stanford.edu/notes2020spring/cs229-notes7a.pdf). The first part of Chapter 9 of _Pattern Recognition and Machine Learning_ by Christopher M. Bishop also gives a good overview of the algorithm, as well as its connection to the Expection Maximization (EM) algorithm.\n",
    "\n",
    "We have provided some skeleton code for the classifier, along with a couple of utility functions in the [k_means.py](./k_means.py) module. Please fill out the functions marked with `TODO` and feel free to add extra constructor arguments as you see fit (just make sure the default constructor solves the first dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by loading necessary packages. Below follows a short description of the imported modules:\n",
    "\n",
    "- `numpy` is the defacto python package for numerical calculation. Most other numerical libraries (including pandas) is based on numpy.\n",
    "- `pandas` is a widely used package for manipulating (mostly) tabular data\n",
    "- `matplotlib` is the most used plotting library for python\n",
    "- `seaborn` contains several convience functions for matplotlib and integrates very well with pandas\n",
    "- `k_means` refers to the module in this folder that should be further implemented by you.\n",
    "\n",
    "Note: The `%autoreload` statement is an [IPython magic command](https://ipython.readthedocs.io/en/stable/interactive/magics.html) that automatically reloads the newest version of all imported modules within the cell. This means that you can edit the `k_means.py` file and just rerun this cell to get the updated version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import k_means as km # <-- Your implementation\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] First Dataset\n",
    "\n",
    "The first dataset is a simple problem that is well suited for K-Means. It consists of 500 datapoints ($x_0, x_1 \\in \\mathbb{R}$) that should be partitioned into two clusters.\n",
    "\n",
    "### [1.1] Load Data\n",
    "\n",
    "We begin by loading data from a .csv file located in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv('data_1.csv')\n",
    "data_1.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.2] Visualize\n",
    "\n",
    "Since the data is 2-dimensional, it lends itself nicely to visualization with a scatter plot. From this, it should be evident what a sensible clustering should look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.scatterplot(x='x0', y='x1', data=data_1)\n",
    "plt.xlim(0, 1); plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [1.3] Fit and Evaluate\n",
    "\n",
    "Next we fit and evaluate your K-Means clustering model over the dataset. It should work with the default constructor, but it is perfectly fine if you make the default constructor configure the algorithm for two centroids. \n",
    "\n",
    "We will quantitatively evaluate the solution according to _distortion_ and the _silhouette score_ (both assuming a euclidean distance metric).\n",
    "\n",
    "- The distortion measure is equal to the sum of squared distances between each point and the centroid it is assigned to. It favors cohesive clusters, i.e. clusters where all points are close to their centroids, and is used as a minimization objective by K-Means.\n",
    "\n",
    "- The [silhouette score](https://en.wikipedia.org/wiki/Silhouette_(clustering) measures both cluster cohesion and separation. I.e., it also accounts for to what degree each cluster is isolated from other clusters. It takes on values in the range (-1, 1) and is subject to maximization.\n",
    "\n",
    "Note that `.fit`, `.predict`, and `.get_centroids` will crash until you implement these two methods in [k_means.py](./k_means.py). The `.get_centroids` method is used fetch the cluster centroids which are visualized as stars in the figure.\n",
    "\n",
    "Assuming a standard implementation of K-means, you should expect to get a sihouette score of ~0.67 and a distortion measure of ~8.8. You can also verify that everything is working as it should by inspecting the generated figure. A working algorithm should generate centroids such that all the points with $x_0 < 0.5$ (approximately) are assigned to one cluster and the remaining are assigned to the other.\n",
    "\n",
    "**Accepted Performance:** Both clusters should be correctly identified 100% of the time when doing randomized initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model \n",
    "X = data_1[['x0', 'x1']]\n",
    "model_1 = km.KMeans() # <-- Should work with default constructor  \n",
    "model_1.fit(X)\n",
    "\n",
    "# Compute Silhouette Score \n",
    "z = model_1.predict(X)\n",
    "print(f'Silhouette Score: {km.euclidean_silhouette(X, z) :.3f}')\n",
    "print(f'Distortion: {km.euclidean_distortion(X, z) :.3f}')\n",
    "\n",
    "# Plot cluster assignments\n",
    "C = model_1.get_centroids()\n",
    "K = len(C)\n",
    "_, ax = plt.subplots(figsize=(5, 5), dpi=100)\n",
    "sns.scatterplot(x='x0', y='x1', hue=z, hue_order=range(K), palette='tab10', data=X, ax=ax);\n",
    "sns.scatterplot(x=C[:,0], y=C[:,1], hue=range(K), palette='tab10', marker='*', s=250, edgecolor='black', ax=ax)\n",
    "ax.legend().remove();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Second Dataset\n",
    "\n",
    "The second dataset is superficially similar to the first one. The goal is still to partition a two-dimensional dataset into mutually exlusive groups, but it is designed to be a bit more challenging.\n",
    "\n",
    "### [2.1] Load Data\n",
    "\n",
    "This dataset can also be found in a .csv file in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv('data_2.csv')\n",
    "data_2.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.2] Visualize Data\n",
    "\n",
    "As can be seen, there are substantially more clusters in this dataset. We generated a total of 10 clusters that your algorithm should be able to identify. It is ok if you pass information about the number of clusters to your model during instantiation, but it should be able to initialize itself and identify a good clustering without any other external information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "sns.scatterplot(x='x0', y='x1', data=data_2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [2.3] Fit and Evaluate\n",
    "\n",
    "Again, we fit the model to the data, measure distortion and silhouette score, and visualize the resulting clusters. You may experience that the algorithm you implemented for the first dataset fails to find all the clusters, at least consistently. \n",
    "\n",
    "Feel free to add extra functionality to the algorithm and/or the data preprocessing pipeline that improve performance. It might be useful to run the algorithm for one iteration at the time and plot the resulting clustering to get a better idea of what is going on. \n",
    "\n",
    "**Accepted Performance:** All 10 clusters should be found at least 50% of the time when doing randomized initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model \n",
    "X = data_2[['x0', 'x1']]\n",
    "model_2 = km.KMeans()  # <-- Feel free to add hyperparameters \n",
    "model_2.fit(X)\n",
    "\n",
    "# Compute Silhouette Score \n",
    "z = model_2.predict(X)\n",
    "print(f'Distortion: {km.euclidean_distortion(X, z) :.3f}')\n",
    "print(f'Silhouette Score: {km.euclidean_silhouette(X, z) :.3f}')\n",
    "\n",
    "# Plot cluster assignments\n",
    "C = model_2.get_centroids()\n",
    "K = len(C)\n",
    "_, ax = plt.subplots(figsize=(5, 5), dpi=100)\n",
    "sns.scatterplot(x='x0', y='x1', hue=z, hue_order=range(K), palette='tab10', data=X, ax=ax);\n",
    "sns.scatterplot(x=C[:,0], y=C[:,1], hue=range(K), palette='tab10', marker='*', s=250, edgecolor='black', ax=ax)\n",
    "ax.legend().remove();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Further Steps (optional)\n",
    "\n",
    "If you're done with the assignment but want to some more challenges; consider the following:\n",
    "\n",
    "- Modify your clustering algorithm so that the user no longer has to enter the number of clusters manually.\n",
    "- K-means makes hard cluster assignments. Try implementing the [EM-algorithm](https://en.wikipedia.org/wiki/Expectation–maximization_algorithm) to fit a gaussian mixture model to the data above.\n",
    "- Implement a clustering algorithm that solves the dataset below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bonus = pd.read_csv('data_bonus.csv')\n",
    "plt.figure(figsize=(5, 5))\n",
    "sns.scatterplot(x='x0', y='x1', data=data_bonus);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
